{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a34181b4-0136-47b7-a025-6df87b80f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要求Python ≥3.5 \n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# 要求Scikit-Learn ≥0.20\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6632ff54-8795-4199-a55b-488fddb013a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.environ.get(\"BASE_PATH\",'./data/')\n",
    "data_path = os.path.join(base_path + \"lab12/\") \n",
    "result_path = \"result\"\n",
    "img_path = \"img\"\n",
    "\n",
    "os.makedirs(result_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8d1a402-1d9d-40c8-bea7-c518fe606c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(result_path, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0584d4d8-5c5a-449e-8fb3-f485a54a1a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b287735-5fb5-4be1-a8b8-fc9e58e8da17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37922fde-cde9-4215-934b-bc3bdd6249ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a980a82-6298-4ded-a2dd-215027cf7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing(data_home=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6bf88456-1e86-44af-b1de-a897aebe6b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, \n",
    "                                                              housing.target, \n",
    "                                                              random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, \n",
    "                                                      y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bba23f40-b553-41c5-810f-9381c0760ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eec17dad-d733-48aa-a982-354c3cc50650",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56010599-5d3a-42f9-9eea-a27f092dc0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    # 输入层\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    # 构建多层隐藏层\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    # 输出层\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    # 优化器\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    # 模型编译\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96409778-a677-41df-bc92-b9654fcb88ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3304db4-8a55-44fe-bc53-8b07d837a0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 1.6087 - val_loss: 2.0853\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.5923 - val_loss: 1.6630\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.5034 - val_loss: 0.8161\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4708 - val_loss: 0.5719\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4511 - val_loss: 0.4226\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4393 - val_loss: 0.6847\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4345 - val_loss: 0.4404\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4256 - val_loss: 0.4058\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4202 - val_loss: 0.4518\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4153 - val_loss: 0.4980\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4122 - val_loss: 0.3970\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4080 - val_loss: 0.3761\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4038 - val_loss: 0.5864\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4036 - val_loss: 0.4126\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3991 - val_loss: 0.3687\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3959 - val_loss: 0.3692\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3934 - val_loss: 0.4698\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3936 - val_loss: 0.5081\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3896 - val_loss: 0.5660\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3903 - val_loss: 0.3682\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3856 - val_loss: 0.3800\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3832 - val_loss: 0.8898\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3856 - val_loss: 0.9120\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3831 - val_loss: 0.7363\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3834 - val_loss: 1.0551\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3828 - val_loss: 1.5216\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3912 - val_loss: 1.1618\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3804 - val_loss: 1.5882\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3851 - val_loss: 0.9686\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3767 - val_loss: 1.0468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7cd9131b70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49892b64-03f2-4df1-9379-ffc856624831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 11us/sample - loss: 0.3721\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1d2be28-fe3e-4f45-b10f-0c7bd93684f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75574756, 1.6282668 , 3.842754  ], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = keras_reg.predict(X_test[:3])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "855373ae-4b0e-4c70-9d90-47163b7f6496",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d87c11e5-4cfd-48fa-a67a-b3f9f5835d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.8516 - val_loss: 0.5417\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5069 - val_loss: 0.4385\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4447 - val_loss: 0.4095\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4202 - val_loss: 0.3839\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4073 - val_loss: 0.3824\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4040 - val_loss: 0.3725\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3991 - val_loss: 0.3669\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3940 - val_loss: 0.3706\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3909 - val_loss: 0.3816\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3900 - val_loss: 0.3623\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3891 - val_loss: 0.3597\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3867 - val_loss: 0.3570\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3870 - val_loss: 0.3594\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3857 - val_loss: 0.3689\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3922 - val_loss: 0.3642\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3874 - val_loss: 0.3608\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3827 - val_loss: 0.3591\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3824 - val_loss: 0.3568\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3824 - val_loss: 0.3545\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3820 - val_loss: 0.3551\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3812 - val_loss: 0.3523\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3804 - val_loss: 0.3550\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3811 - val_loss: 0.3534\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3796 - val_loss: 0.3648\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3800 - val_loss: 0.3531\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3826 - val_loss: 0.3632\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3849 - val_loss: 0.3559\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3795 - val_loss: 0.3511\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3785 - val_loss: 0.3614\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3772 - val_loss: 0.3565\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3782 - val_loss: 0.3484\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3767 - val_loss: 0.3512\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3773 - val_loss: 0.3520\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3770 - val_loss: 0.3619\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3797 - val_loss: 0.3458\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3775 - val_loss: 0.3504\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3769 - val_loss: 0.3527\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3772 - val_loss: 0.3512\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 19us/sample - loss: 0.3769 - val_loss: 0.3459\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 20us/sample - loss: 0.3774 - val_loss: 0.3465\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 21us/sample - loss: 0.3760 - val_loss: 0.3658\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 21us/sample - loss: 0.3775 - val_loss: 0.3583\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 21us/sample - loss: 0.3785 - val_loss: 0.3506\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 21us/sample - loss: 0.3763 - val_loss: 0.3492\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 21us/sample - loss: 0.3771 - val_loss: 0.3520\n",
      "3870/3870 [==============================] - 0s 9us/sample - loss: 0.3918\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   7.9s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6871 - val_loss: 0.9796\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4453 - val_loss: 0.4134\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4405 - val_loss: 0.4255\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4280 - val_loss: 0.4274\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4298 - val_loss: 0.3975\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4274 - val_loss: 0.4369\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4197 - val_loss: 0.3826\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4218 - val_loss: 0.4177\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4167 - val_loss: 0.3924\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4161 - val_loss: 0.3875\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4272 - val_loss: 0.3943\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4134 - val_loss: 0.5514\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4111 - val_loss: 0.3752\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4078 - val_loss: 0.7117\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4044 - val_loss: 0.5430\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4051 - val_loss: 0.5105\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4039 - val_loss: 0.4515\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4061 - val_loss: 0.4260\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4010 - val_loss: 0.5428\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4015 - val_loss: 0.6600\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3987 - val_loss: 0.8891\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4092 - val_loss: 0.4403\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4015 - val_loss: 0.6423\n",
      "3870/3870 [==============================] - 0s 10us/sample - loss: 0.4118\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   4.2s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 1.0930 - val_loss: 0.6778\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5246 - val_loss: 0.4467\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4735 - val_loss: 0.4218\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4571 - val_loss: 0.4122\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4494 - val_loss: 0.4107\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4472 - val_loss: 0.4131\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4449 - val_loss: 0.4047\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4425 - val_loss: 0.4169\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4398 - val_loss: 0.4093\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4399 - val_loss: 0.4169\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4358 - val_loss: 0.4122\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4339 - val_loss: 0.3966\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4316 - val_loss: 0.4043\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4295 - val_loss: 0.4268\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4250 - val_loss: 0.3884\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4226 - val_loss: 0.3978\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4185 - val_loss: 0.4049\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4165 - val_loss: 0.3969\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4133 - val_loss: 0.4102\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4130 - val_loss: 0.3831\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4111 - val_loss: 0.4041\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4109 - val_loss: 0.3803\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4088 - val_loss: 0.4585\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4082 - val_loss: 0.4224\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4066 - val_loss: 0.4104\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4062 - val_loss: 0.3799\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4043 - val_loss: 0.4554\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4039 - val_loss: 0.3812\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4050 - val_loss: 0.4472\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4058 - val_loss: 0.3717\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4034 - val_loss: 0.3811\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4011 - val_loss: 0.4256\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4026 - val_loss: 0.3761\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4021 - val_loss: 0.4074\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4009 - val_loss: 0.4476\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4016 - val_loss: 0.4140\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4076 - val_loss: 0.4193\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4122 - val_loss: 0.3905\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4062 - val_loss: 0.3847\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4051 - val_loss: 0.4141\n",
      "3870/3870 [==============================] - 0s 9us/sample - loss: 0.3882\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   7.1s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 1.1746 - val_loss: 3.3025\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5724 - val_loss: 10.8568\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.6514 - val_loss: 6.9845\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.5193 - val_loss: 1.7634\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4233 - val_loss: 0.4084\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3955 - val_loss: 0.4174\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3850 - val_loss: 0.3798\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3774 - val_loss: 0.3869\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3705 - val_loss: 0.3896\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3642 - val_loss: 0.3782\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3597 - val_loss: 0.3641\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3564 - val_loss: 0.3603\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3514 - val_loss: 0.3532\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3485 - val_loss: 0.3519\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3462 - val_loss: 0.3559\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3433 - val_loss: 0.3606\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3415 - val_loss: 0.3715\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3389 - val_loss: 0.3594\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3370 - val_loss: 0.3366\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3356 - val_loss: 0.3356\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3332 - val_loss: 0.3323\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3307 - val_loss: 0.3484\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3286 - val_loss: 0.3274\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3264 - val_loss: 0.3524\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3263 - val_loss: 0.3318\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3238 - val_loss: 0.3486\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3224 - val_loss: 0.3218\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3225 - val_loss: 0.3423\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3200 - val_loss: 0.3171\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3181 - val_loss: 0.3195\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3168 - val_loss: 0.3453\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3159 - val_loss: 0.3143\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3155 - val_loss: 0.3129\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3132 - val_loss: 0.3418\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3119 - val_loss: 0.3125\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3097 - val_loss: 0.3456\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3092 - val_loss: 0.3089\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3084 - val_loss: 0.3481\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3076 - val_loss: 0.3070\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3062 - val_loss: 0.3335\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3053 - val_loss: 0.3314\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3038 - val_loss: 0.3248\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3028 - val_loss: 0.3232\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3024 - val_loss: 0.3023\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3006 - val_loss: 0.3035\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3005 - val_loss: 0.3350\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.2989 - val_loss: 0.3037\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.2989 - val_loss: 0.3069\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.2968 - val_loss: 0.3243\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.2964 - val_loss: 0.3104\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.2963 - val_loss: 0.2937\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.2943 - val_loss: 0.2945\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.2938 - val_loss: 0.3288\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.2922 - val_loss: 0.3022\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.2920 - val_loss: 0.3223\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.2911 - val_loss: 0.3179\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.2899 - val_loss: 0.3073\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.2897 - val_loss: 0.3304\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.2885 - val_loss: 0.3120\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.2873 - val_loss: 0.3146\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.2871 - val_loss: 0.3073\n",
      "3870/3870 [==============================] - 0s 9us/sample - loss: 0.3258\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  11.6s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 1.0291 - val_loss: 2.1380\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5269 - val_loss: 0.4468\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4488 - val_loss: 0.4229\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4126 - val_loss: 0.3784\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3957 - val_loss: 0.4083\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3815 - val_loss: 0.5817\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3724 - val_loss: 0.7897\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3673 - val_loss: 0.6631\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3611 - val_loss: 1.0162\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3579 - val_loss: 0.7782\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3519 - val_loss: 0.8060\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3493 - val_loss: 0.7330\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3463 - val_loss: 0.8729\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3433 - val_loss: 0.9403\n",
      "3870/3870 [==============================] - 0s 12us/sample - loss: 0.3715\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=   3.4s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 1.3099 - val_loss: 7.2344\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5764 - val_loss: 9.5587\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5298 - val_loss: 8.0089\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5276 - val_loss: 0.5894\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.4075 - val_loss: 0.4749\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3930 - val_loss: 0.4164\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3831 - val_loss: 0.4194\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3771 - val_loss: 0.4220\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3712 - val_loss: 0.3979\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3673 - val_loss: 0.4096\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3632 - val_loss: 0.3982\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3603 - val_loss: 0.3731\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3555 - val_loss: 0.3737\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3532 - val_loss: 0.3623\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3504 - val_loss: 0.3535\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3474 - val_loss: 0.3695\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3460 - val_loss: 0.3532\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3438 - val_loss: 0.3904\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3423 - val_loss: 0.3548\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3398 - val_loss: 0.3787\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3382 - val_loss: 0.3334\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3359 - val_loss: 0.3509\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3339 - val_loss: 0.3584\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3336 - val_loss: 0.3567\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3320 - val_loss: 0.3408\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3301 - val_loss: 0.3190\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3279 - val_loss: 0.3625\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3269 - val_loss: 0.3413\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3258 - val_loss: 0.3164\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3253 - val_loss: 0.3332\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3231 - val_loss: 0.3549\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3235 - val_loss: 0.3194\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3222 - val_loss: 0.3217\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3204 - val_loss: 0.3153\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3191 - val_loss: 0.3214\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3174 - val_loss: 0.3561\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3196 - val_loss: 0.3234\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3166 - val_loss: 0.3171\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3158 - val_loss: 0.3489\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3153 - val_loss: 0.3053\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3140 - val_loss: 0.3235\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3116 - val_loss: 0.3414\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3116 - val_loss: 0.3170\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3117 - val_loss: 0.3298\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3118 - val_loss: 0.3143\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3085 - val_loss: 0.3027\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3079 - val_loss: 0.3216\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3071 - val_loss: 0.3087\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3065 - val_loss: 0.3041\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3062 - val_loss: 0.3040\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3056 - val_loss: 0.3361\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3029 - val_loss: 0.3184\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3031 - val_loss: 0.3208\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3020 - val_loss: 0.3548\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3014 - val_loss: 0.3082\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.2996 - val_loss: 0.3291\n",
      "3870/3870 [==============================] - 0s 10us/sample - loss: 0.3113\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  11.4s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 3.2822 - val_loss: 4.8988\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 1.8193 - val_loss: 4.1515\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 1.2415 - val_loss: 2.6149\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.9784 - val_loss: 1.4164\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.8491 - val_loss: 0.9565\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7834 - val_loss: 0.7972\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7461 - val_loss: 0.7280\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7214 - val_loss: 0.6947\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7029 - val_loss: 0.6781\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6875 - val_loss: 0.6720\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6744 - val_loss: 0.6520\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6623 - val_loss: 0.6461\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6512 - val_loss: 0.6340\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6407 - val_loss: 0.6284\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6311 - val_loss: 0.6099\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6216 - val_loss: 0.6077\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6130 - val_loss: 0.5958ETA: 0s - loss: 0.618\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6047 - val_loss: 0.5808\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5965 - val_loss: 0.5804\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5890 - val_loss: 0.5763\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5819 - val_loss: 0.5608\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5748 - val_loss: 0.5517\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5681 - val_loss: 0.5448\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5616 - val_loss: 0.5360\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5553 - val_loss: 0.5323\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5493 - val_loss: 0.5267\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5435 - val_loss: 0.5219\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5381 - val_loss: 0.5111\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5327 - val_loss: 0.5111\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5276 - val_loss: 0.5074\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5227 - val_loss: 0.5031\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5180 - val_loss: 0.4954\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.5134 - val_loss: 0.4879\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5090 - val_loss: 0.4815\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5047 - val_loss: 0.4797\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5007 - val_loss: 0.4761\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4968 - val_loss: 0.4716\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4930 - val_loss: 0.4671\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4894 - val_loss: 0.4631\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4858 - val_loss: 0.4597\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4826 - val_loss: 0.4545\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4793 - val_loss: 0.4512\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4763 - val_loss: 0.4479\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4734 - val_loss: 0.4442\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4706 - val_loss: 0.4414\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4679 - val_loss: 0.4390\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4654 - val_loss: 0.4365\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4629 - val_loss: 0.4340\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4606 - val_loss: 0.4317\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4583 - val_loss: 0.4299\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.457 - 0s 24us/sample - loss: 0.4562 - val_loss: 0.4275\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4541 - val_loss: 0.4261\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4521 - val_loss: 0.4246\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4502 - val_loss: 0.4230\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4484 - val_loss: 0.4203\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4467 - val_loss: 0.4195\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4450 - val_loss: 0.4177\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4434 - val_loss: 0.4159\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4419 - val_loss: 0.4157\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4404 - val_loss: 0.4135\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4390 - val_loss: 0.4120\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4377 - val_loss: 0.4119\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4363 - val_loss: 0.4105\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4351 - val_loss: 0.4093\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4339 - val_loss: 0.4087\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4327 - val_loss: 0.4081\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4315 - val_loss: 0.4074\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4304 - val_loss: 0.4086\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4293 - val_loss: 0.4070\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4283 - val_loss: 0.4052\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4273 - val_loss: 0.4073\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4263 - val_loss: 0.4055\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4254 - val_loss: 0.4052\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4245 - val_loss: 0.4045\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4235 - val_loss: 0.4064\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4227 - val_loss: 0.4052\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4218 - val_loss: 0.4052\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4210 - val_loss: 0.4037\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4202 - val_loss: 0.4042\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4194 - val_loss: 0.4019\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4186 - val_loss: 0.4015\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4179 - val_loss: 0.4041\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4171 - val_loss: 0.4044\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4164 - val_loss: 0.4017\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.416 - 0s 24us/sample - loss: 0.4157 - val_loss: 0.4017\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4150 - val_loss: 0.4013\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4144 - val_loss: 0.3999\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4137 - val_loss: 0.4013\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4130 - val_loss: 0.3997\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4124 - val_loss: 0.3998\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4117 - val_loss: 0.3996\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4111 - val_loss: 0.3988\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4105 - val_loss: 0.4000\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4098 - val_loss: 0.3990\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4092 - val_loss: 0.3971\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4086 - val_loss: 0.3956\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4081 - val_loss: 0.3983\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4075 - val_loss: 0.3978\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4069 - val_loss: 0.3975\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4064 - val_loss: 0.3971\n",
      "3870/3870 [==============================] - 0s 14us/sample - loss: 0.4185\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  19.0s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 2.9732 - val_loss: 5.4551\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 1.4976 - val_loss: 6.4862\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 1.0344 - val_loss: 6.6435\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.8729 - val_loss: 6.2538\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.8054 - val_loss: 5.6438\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7698 - val_loss: 5.0576\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7462 - val_loss: 4.5026\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7281 - val_loss: 4.0355\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7127 - val_loss: 3.6016\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6990 - val_loss: 3.2370ETA: 0s - loss: 0.689\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6861 - val_loss: 2.9065\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6742 - val_loss: 2.6300\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6627 - val_loss: 2.3750\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6519 - val_loss: 2.1672\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6415 - val_loss: 1.9765\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6316 - val_loss: 1.8043\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6223 - val_loss: 1.6472\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6133 - val_loss: 1.5057\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6048 - val_loss: 1.3852\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5966 - val_loss: 1.2799\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5887 - val_loss: 1.1839\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5812 - val_loss: 1.1049\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5741 - val_loss: 1.0315\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5672 - val_loss: 0.9626\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5607 - val_loss: 0.9055\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5545 - val_loss: 0.8554\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5486 - val_loss: 0.8118\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5429 - val_loss: 0.7723\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5375 - val_loss: 0.7376\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5324 - val_loss: 0.7068\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5275 - val_loss: 0.6810\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5228 - val_loss: 0.6595\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5183 - val_loss: 0.6367\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5140 - val_loss: 0.6166\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5100 - val_loss: 0.6027\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5060 - val_loss: 0.5935\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5024 - val_loss: 0.5772\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4988 - val_loss: 0.5649\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4954 - val_loss: 0.5565\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4921 - val_loss: 0.5477\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4890 - val_loss: 0.5415\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4861 - val_loss: 0.5361\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4833 - val_loss: 0.5306\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4806 - val_loss: 0.5274\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4780 - val_loss: 0.5251\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4754 - val_loss: 0.5238\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4732 - val_loss: 0.5195\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4708 - val_loss: 0.5165\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4687 - val_loss: 0.5160\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4666 - val_loss: 0.5165\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4645 - val_loss: 0.5181\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4626 - val_loss: 0.5212\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4607 - val_loss: 0.5200\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4589 - val_loss: 0.5225\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4572 - val_loss: 0.5250\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4556 - val_loss: 0.5264\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4540 - val_loss: 0.5311\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4524 - val_loss: 0.5374\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4510 - val_loss: 0.5418\n",
      "3870/3870 [==============================] - 0s 14us/sample - loss: 0.4578\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  11.5s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 4.485 - 0s 59us/sample - loss: 4.0345 - val_loss: 4.5759\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 2.1074 - val_loss: 3.9453\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 1.3383 - val_loss: 2.3021\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.9951 - val_loss: 1.5586\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.8408 - val_loss: 1.0451\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.7673 - val_loss: 0.8093\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.7288 - val_loss: 0.7202\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7052 - val_loss: 0.6906\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6880 - val_loss: 0.6777\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6741 - val_loss: 0.6676\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6618 - val_loss: 0.6623\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6505 - val_loss: 0.6493\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6399 - val_loss: 0.6355\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6299 - val_loss: 0.6238\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6204 - val_loss: 0.6137\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6113 - val_loss: 0.6023\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.596 - 0s 24us/sample - loss: 0.6025 - val_loss: 0.5967\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5944 - val_loss: 0.5816\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.596 - 0s 24us/sample - loss: 0.5865 - val_loss: 0.5711\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5789 - val_loss: 0.5668\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5719 - val_loss: 0.5566\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5650 - val_loss: 0.5496\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5583 - val_loss: 0.5446\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5520 - val_loss: 0.5380\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5460 - val_loss: 0.5289\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5403 - val_loss: 0.5228\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5347 - val_loss: 0.5158\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5294 - val_loss: 0.5112\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5244 - val_loss: 0.5053\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5196 - val_loss: 0.5001\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5150 - val_loss: 0.4956\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5106 - val_loss: 0.4909\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5064 - val_loss: 0.4867\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5024 - val_loss: 0.4831\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4986 - val_loss: 0.4788\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4949 - val_loss: 0.4754\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4915 - val_loss: 0.4716\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.4881 - val_loss: 0.4680\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4849 - val_loss: 0.4653\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4818 - val_loss: 0.4623\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4789 - val_loss: 0.4604\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4761 - val_loss: 0.4567\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4734 - val_loss: 0.4537\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4709 - val_loss: 0.4518\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4684 - val_loss: 0.4498\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4660 - val_loss: 0.4482\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4637 - val_loss: 0.4467\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4615 - val_loss: 0.4433\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4595 - val_loss: 0.4417\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4574 - val_loss: 0.4402\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4555 - val_loss: 0.4384\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4536 - val_loss: 0.4381\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4518 - val_loss: 0.4358\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4501 - val_loss: 0.4346\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4483 - val_loss: 0.4331\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4467 - val_loss: 0.4320\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4451 - val_loss: 0.4344\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4436 - val_loss: 0.4327\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4421 - val_loss: 0.4299\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4407 - val_loss: 0.4281\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4393 - val_loss: 0.4274\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4379 - val_loss: 0.4256\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4366 - val_loss: 0.4231\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4353 - val_loss: 0.4230\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4341 - val_loss: 0.4253\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4329 - val_loss: 0.4261\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4317 - val_loss: 0.4281\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4306 - val_loss: 0.4213\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4294 - val_loss: 0.4235\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4283 - val_loss: 0.4255\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4273 - val_loss: 0.4203\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4262 - val_loss: 0.4223\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4252 - val_loss: 0.4194\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4242 - val_loss: 0.4190\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4233 - val_loss: 0.4190\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4223 - val_loss: 0.4183\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4214 - val_loss: 0.4197\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4205 - val_loss: 0.4154\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4197 - val_loss: 0.4182\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4188 - val_loss: 0.4209\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4180 - val_loss: 0.4214\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4172 - val_loss: 0.4148\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4163 - val_loss: 0.4158\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4155 - val_loss: 0.4191\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4148 - val_loss: 0.4159\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4141 - val_loss: 0.4160\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4134 - val_loss: 0.4132\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4126 - val_loss: 0.4101\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4120 - val_loss: 0.4145\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4113 - val_loss: 0.4118\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4107 - val_loss: 0.4122\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4100 - val_loss: 0.4152\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4094 - val_loss: 0.4108\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4088 - val_loss: 0.4121\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4082 - val_loss: 0.4148\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4077 - val_loss: 0.4112\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4071 - val_loss: 0.4118\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4065 - val_loss: 0.4187\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.4062\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  18.8s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 1.8273 - val_loss: 1.6046\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.7146 - val_loss: 1.3142\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.6140 - val_loss: 0.6036\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5625 - val_loss: 0.5177\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.5232 - val_loss: 0.4955\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4925 - val_loss: 0.4675\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4718 - val_loss: 0.4740\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4540 - val_loss: 0.4356\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4411 - val_loss: 0.4304\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4307 - val_loss: 0.4066\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4216 - val_loss: 0.4104\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4148 - val_loss: 0.3906\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4081 - val_loss: 0.3942\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4019 - val_loss: 0.4146\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3972 - val_loss: 0.4128\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3929 - val_loss: 0.3960\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3890 - val_loss: 0.3744\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3854 - val_loss: 0.3868\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3817 - val_loss: 0.3756\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3788 - val_loss: 0.3845\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3756 - val_loss: 0.3868\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3728 - val_loss: 0.4236\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3709 - val_loss: 0.4113\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3686 - val_loss: 0.3788\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3664 - val_loss: 0.3766\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3641 - val_loss: 0.3558\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3619 - val_loss: 0.4530\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3607 - val_loss: 0.3874\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3581 - val_loss: 0.4460\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3576 - val_loss: 0.3559\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3558 - val_loss: 0.3832\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3540 - val_loss: 0.3978\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3524 - val_loss: 0.3432\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3515 - val_loss: 0.3782\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3493 - val_loss: 0.4350\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3491 - val_loss: 0.3410\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3476 - val_loss: 0.5315\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3481 - val_loss: 0.3713\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3455 - val_loss: 0.6865\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3470 - val_loss: 0.3863\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3444 - val_loss: 0.6178\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3445 - val_loss: 0.3373\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3410 - val_loss: 0.6030\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3415 - val_loss: 0.3480\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3389 - val_loss: 0.4803\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3389 - val_loss: 0.3664\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3380 - val_loss: 0.3695\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3367 - val_loss: 0.3299\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3359 - val_loss: 0.5253\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3367 - val_loss: 0.3359\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3334 - val_loss: 0.4667\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3342 - val_loss: 0.3543\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3330 - val_loss: 0.5783\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3334 - val_loss: 0.4410\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3325 - val_loss: 0.5690\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3322 - val_loss: 0.3240\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3298 - val_loss: 0.3615\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3290 - val_loss: 0.3242\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3282 - val_loss: 0.5247\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3286 - val_loss: 0.3479\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3280 - val_loss: 0.7002\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3301 - val_loss: 0.3729\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3268 - val_loss: 0.5031\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3260 - val_loss: 0.4058\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3259 - val_loss: 0.6210\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3260 - val_loss: 0.5151\n",
      "3870/3870 [==============================] - 0s 10us/sample - loss: 0.3561\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  12.9s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 1.7271 - val_loss: 13.4037\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.7126 - val_loss: 5.1121\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.6151 - val_loss: 1.9822\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5517 - val_loss: 0.8070\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5066 - val_loss: 0.4711\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.4741 - val_loss: 0.4473\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4509 - val_loss: 0.5082\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4343 - val_loss: 0.5020\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4224 - val_loss: 0.4948\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4133 - val_loss: 0.4677\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4055 - val_loss: 0.3968\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3997 - val_loss: 0.3809\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3947 - val_loss: 0.3696\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3905 - val_loss: 0.3773\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3862 - val_loss: 0.4038\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3827 - val_loss: 0.4602\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3799 - val_loss: 0.4847\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3769 - val_loss: 0.5545\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3742 - val_loss: 0.5467\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3716 - val_loss: 0.5423\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3692 - val_loss: 0.5470\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3675 - val_loss: 0.6425\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3650 - val_loss: 0.6824\n",
      "3870/3870 [==============================] - 0s 14us/sample - loss: 0.3751\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=   5.4s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 2.2163 - val_loss: 5.9248\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.7330 - val_loss: 0.6180\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5985 - val_loss: 0.5496\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5569 - val_loss: 0.5112\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5214 - val_loss: 0.4817\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4950 - val_loss: 0.4587\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4736 - val_loss: 0.4416\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4575 - val_loss: 0.4247\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4443 - val_loss: 0.4159\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4343 - val_loss: 0.4083\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4269 - val_loss: 0.4143\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4195 - val_loss: 0.4110\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4148 - val_loss: 0.3973\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4104 - val_loss: 0.3948\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4055 - val_loss: 0.4055\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4013 - val_loss: 0.4066\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3992 - val_loss: 0.3774\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3946 - val_loss: 0.3929\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3921 - val_loss: 0.4113\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3895 - val_loss: 0.3927\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3867 - val_loss: 0.3780\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3844 - val_loss: 0.3954\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3820 - val_loss: 0.3781\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3801 - val_loss: 0.3995\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3784 - val_loss: 0.3712\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3762 - val_loss: 0.3630\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3752 - val_loss: 0.3766\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3731 - val_loss: 0.3829\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3714 - val_loss: 0.3740\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3706 - val_loss: 0.3868\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3683 - val_loss: 0.3743\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3678 - val_loss: 0.3793\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3663 - val_loss: 0.3753\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3650 - val_loss: 0.3967\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3645 - val_loss: 0.3644\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3629 - val_loss: 0.3640\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3629\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=   7.9s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 1.1268 - val_loss: 1.0075\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.7397 - val_loss: 0.7509\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5614 - val_loss: 8.8131\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 1.2157 - val_loss: 13.8224\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6820 - val_loss: 115.5720\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 1.2300 - val_loss: 391.1262\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 3.8997 - val_loss: 3541.4033\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 29.0359 - val_loss: 13903.8112\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 360.7935 - val_loss: 63732.3341\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 1367.7009 - val_loss: 277558.5242\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 590.4044 - val_loss: 1309652.4561\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 53378.2843 - val_loss: 5757326.8228\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 14948.7172\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   2.5s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.9021 - val_loss: 12.8204\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5388 - val_loss: 13.7885\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5241 - val_loss: 15.0945\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5111 - val_loss: 16.6534\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5107 - val_loss: 12.6486\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5118 - val_loss: 11.4481\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5058 - val_loss: 9.4463\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5083 - val_loss: 20.3698\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5100 - val_loss: 13.0206\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5092 - val_loss: 21.1010\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5060 - val_loss: 20.7008\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5146 - val_loss: 17.2505\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5073 - val_loss: 24.3896\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5122 - val_loss: 14.5605\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5068 - val_loss: 24.9795\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5136 - val_loss: 14.3167\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5178 - val_loss: 21.7666\n",
      "3870/3870 [==============================] - 0s 10us/sample - loss: 1.0444\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   3.4s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 1.1194 - val_loss: 0.8956\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.9905 - val_loss: 1.3815\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.6816 - val_loss: 914.2335\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 20.1842 - val_loss: 675.2428\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 15.0877 - val_loss: 467.5707\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 9.7549 - val_loss: 330.2570\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 6.3988 - val_loss: 291.1763\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.8280 - val_loss: 85.9403\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 6.9617 - val_loss: 31.2815\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6954 - val_loss: 9.3025\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.7509 - val_loss: 9.3166\n",
      "3870/3870 [==============================] - 0s 10us/sample - loss: 0.6006\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   2.3s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 82us/sample - loss: 1.4016 - val_loss: 1.3046\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5878 - val_loss: 0.8190\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.5116 - val_loss: 0.4841\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4550 - val_loss: 0.4172\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4280 - val_loss: 0.4219\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4102 - val_loss: 0.3885\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3974 - val_loss: 0.3778\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3863 - val_loss: 0.3719\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3783 - val_loss: 0.3593\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3733 - val_loss: 0.4082\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3687 - val_loss: 0.3628\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3639 - val_loss: 0.3459\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3577 - val_loss: 0.4029\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3564 - val_loss: 0.3507\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3520 - val_loss: 0.4277\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3524 - val_loss: 0.3579\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3473 - val_loss: 0.4250\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3470 - val_loss: 0.3896\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3450 - val_loss: 0.3584\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3402 - val_loss: 0.3382\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3376 - val_loss: 0.3743\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3376 - val_loss: 0.3482\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3342 - val_loss: 0.4145\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3332 - val_loss: 0.3264\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3304 - val_loss: 0.3313\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3297 - val_loss: 0.3253\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3282 - val_loss: 0.3222\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3270 - val_loss: 0.4532\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3273 - val_loss: 0.3258\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3259 - val_loss: 0.3920\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3240 - val_loss: 0.3204\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3219 - val_loss: 0.3215\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3218 - val_loss: 0.3192\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3188 - val_loss: 0.3210\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3194 - val_loss: 0.3909\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3190 - val_loss: 0.6148\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3195 - val_loss: 0.4461\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3171 - val_loss: 0.4157\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3169 - val_loss: 0.3631\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3145 - val_loss: 0.3302\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3133 - val_loss: 0.3452\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3145 - val_loss: 0.3803\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3121 - val_loss: 0.3561\n",
      "3870/3870 [==============================] - 0s 10us/sample - loss: 0.3396\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=   9.3s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 1.1163 - val_loss: 1.3210\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5143 - val_loss: 0.5265\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.4534 - val_loss: 0.4085\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.4172 - val_loss: 0.3903\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3959 - val_loss: 0.3689\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3835 - val_loss: 0.3587\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3751 - val_loss: 0.3559\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3690 - val_loss: 0.3528\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3643 - val_loss: 0.3617\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3589 - val_loss: 0.3597\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3561 - val_loss: 0.3767\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3526 - val_loss: 0.3883\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3500 - val_loss: 0.3749\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3466 - val_loss: 0.4272\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3448 - val_loss: 0.4200\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3422 - val_loss: 0.3892\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3412 - val_loss: 0.4722\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3389 - val_loss: 0.4157\n",
      "3870/3870 [==============================] - 0s 13us/sample - loss: 0.3550\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=   4.6s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 1.1795 - val_loss: 2.0041\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5730 - val_loss: 0.9669\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.5001 - val_loss: 0.4790\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4614 - val_loss: 0.5670\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.4388 - val_loss: 0.4277\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4210 - val_loss: 0.3839\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4117 - val_loss: 0.4044\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4022 - val_loss: 0.3971\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3966 - val_loss: 0.4693\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3907 - val_loss: 0.4121\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3848 - val_loss: 0.3524\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3802 - val_loss: 0.3524\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3754 - val_loss: 0.4836\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3728 - val_loss: 0.3420\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3700 - val_loss: 0.3516\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3660 - val_loss: 0.6284\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3666 - val_loss: 0.3349\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3600 - val_loss: 0.3672\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3589 - val_loss: 0.3354\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3543 - val_loss: 0.3554\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3527 - val_loss: 0.4108\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3506 - val_loss: 0.3454\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3472 - val_loss: 0.4126\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3463 - val_loss: 0.4045\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3448 - val_loss: 0.3714\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3419 - val_loss: 0.3616\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3399 - val_loss: 0.4074\n",
      "3870/3870 [==============================] - 0s 10us/sample - loss: 0.3344\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=   6.7s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 86us/sample - loss: 1.7778 - val_loss: 39.1741\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 1.0454 - val_loss: 28.5741\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.9014 - val_loss: 3.2468\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.6047 - val_loss: 0.5200\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.5321 - val_loss: 0.5006\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.5039 - val_loss: 0.4632\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4813 - val_loss: 0.4614\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4637 - val_loss: 0.4282\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4503 - val_loss: 0.4198\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4397 - val_loss: 0.4195\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4316 - val_loss: 0.4103\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4253 - val_loss: 0.4002\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4196 - val_loss: 0.4106\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4163 - val_loss: 0.3925\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4121 - val_loss: 0.4211\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4090 - val_loss: 0.3876\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4063 - val_loss: 0.4159\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4035 - val_loss: 0.4086\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4013 - val_loss: 0.4025\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3992 - val_loss: 0.4087\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3975 - val_loss: 0.3807\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3950 - val_loss: 0.4058\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3937 - val_loss: 0.4051\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3921 - val_loss: 0.3706\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3905 - val_loss: 0.3815\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3888 - val_loss: 0.3981\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3877 - val_loss: 0.3669\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3859 - val_loss: 0.4488\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3853 - val_loss: 0.3908\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3834 - val_loss: 0.4011\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3826 - val_loss: 0.3622\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3815 - val_loss: 0.3718\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3799 - val_loss: 0.4281\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3795 - val_loss: 0.3689\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3779 - val_loss: 0.3630\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3764 - val_loss: 0.4020\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3762 - val_loss: 0.3935\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3750 - val_loss: 0.3559\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3740 - val_loss: 0.4183\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3735 - val_loss: 0.3865\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3719 - val_loss: 0.3873\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3710 - val_loss: 0.3576\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3702 - val_loss: 0.4264\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3699 - val_loss: 0.3534\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3679 - val_loss: 0.4435\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3682 - val_loss: 0.3699\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3670 - val_loss: 0.3951\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3660 - val_loss: 0.3889\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3656 - val_loss: 0.3501\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3648 - val_loss: 0.3622\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3637 - val_loss: 0.3934\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3632 - val_loss: 0.3687\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3625 - val_loss: 0.3470\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3618 - val_loss: 0.3515\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3609 - val_loss: 0.4245\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3610 - val_loss: 0.3558\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3599 - val_loss: 0.3765\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3589 - val_loss: 0.3877\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3587 - val_loss: 0.3797\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3581 - val_loss: 0.3653\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3573 - val_loss: 0.3846\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3570 - val_loss: 0.3479\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3564 - val_loss: 0.3768\n",
      "3870/3870 [==============================] - 0s 12us/sample - loss: 0.3771\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  13.2s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 2.1487 - val_loss: 7.5241\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.7288 - val_loss: 2.8256\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.6306 - val_loss: 1.2511\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.5760 - val_loss: 0.6320\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.5358 - val_loss: 0.4932\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.5059 - val_loss: 0.4958\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4832 - val_loss: 0.5514\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4659 - val_loss: 0.5850\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4526 - val_loss: 0.6249\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4419 - val_loss: 0.5793\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4332 - val_loss: 0.5563\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4262 - val_loss: 0.5341\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4202 - val_loss: 0.4748\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4157 - val_loss: 0.4353\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4109 - val_loss: 0.4138\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4073 - val_loss: 0.4018\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4044 - val_loss: 0.3813\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4013 - val_loss: 0.3761\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3987 - val_loss: 0.3737\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3964 - val_loss: 0.3808\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3944 - val_loss: 0.3924\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3925 - val_loss: 0.4044\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3909 - val_loss: 0.4076\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3890 - val_loss: 0.4266\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3873 - val_loss: 0.4208\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3859 - val_loss: 0.4376\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3844 - val_loss: 0.4475\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3831 - val_loss: 0.4881\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3820 - val_loss: 0.5018\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3951\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=   6.5s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 90us/sample - loss: 1.8945 - val_loss: 4.9029\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.7803 - val_loss: 1.7277\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.6345 - val_loss: 0.5698\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5800 - val_loss: 0.6161\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5393 - val_loss: 0.4964\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.5087 - val_loss: 0.4624\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4856 - val_loss: 0.4430\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4675 - val_loss: 0.4924\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4538 - val_loss: 0.4242\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4439 - val_loss: 0.4687\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4367 - val_loss: 0.4243\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4317 - val_loss: 0.4703\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4271 - val_loss: 0.4932\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4236 - val_loss: 0.3889\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4200 - val_loss: 0.4647\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4185 - val_loss: 0.3891\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4144 - val_loss: 0.4442\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4124 - val_loss: 0.4066\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4107 - val_loss: 0.3891\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4086 - val_loss: 0.4089\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4062 - val_loss: 0.4429\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4052 - val_loss: 0.3753\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4042 - val_loss: 0.4964\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.4044 - val_loss: 0.4181\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4021 - val_loss: 0.3698\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3994 - val_loss: 0.4034\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3979 - val_loss: 0.3747\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3975 - val_loss: 0.5661\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3964 - val_loss: 0.3831\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3935 - val_loss: 0.3707\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3937 - val_loss: 0.5929\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3924 - val_loss: 0.4033\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3915 - val_loss: 0.4791\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3893 - val_loss: 0.4000\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3881 - val_loss: 0.3641\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3871 - val_loss: 0.5495\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3869 - val_loss: 0.4380\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3863 - val_loss: 0.4450\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3859 - val_loss: 0.3756\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3837 - val_loss: 0.4070\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3823 - val_loss: 0.4497\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3818 - val_loss: 0.3639\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3801 - val_loss: 0.3550\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3797 - val_loss: 0.3779\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3788 - val_loss: 0.3703\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3773 - val_loss: 0.3516\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3770 - val_loss: 0.6399\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3778 - val_loss: 0.3735\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3747 - val_loss: 0.5678\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3756 - val_loss: 0.3494\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3735 - val_loss: 0.3585\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3715 - val_loss: 0.5596\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.373 - 0s 26us/sample - loss: 0.3733 - val_loss: 0.3590\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3706 - val_loss: 0.3536\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3705 - val_loss: 0.4314\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3703 - val_loss: 0.4187\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3685 - val_loss: 0.3889\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3687 - val_loss: 0.4206\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3682 - val_loss: 0.4089\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3673 - val_loss: 0.4740\n",
      "3870/3870 [==============================] - 0s 12us/sample - loss: 0.3651\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  13.1s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 99us/sample - loss: 1.2253 - val_loss: 0.6541\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.4875 - val_loss: 0.7504\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.4266 - val_loss: 0.4180\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3942 - val_loss: 0.3871\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3749 - val_loss: 0.3578\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3627 - val_loss: 0.3526\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3537 - val_loss: 0.4255\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3503 - val_loss: 0.3439\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3435 - val_loss: 0.3570\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3380 - val_loss: 0.3323\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3347 - val_loss: 0.3544\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3298 - val_loss: 0.3952\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3303 - val_loss: 0.5146\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3305 - val_loss: 0.6628\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3254 - val_loss: 0.3139\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3203 - val_loss: 0.3246\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3171 - val_loss: 0.4002\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3164 - val_loss: 0.3062\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3128 - val_loss: 0.4263\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3142 - val_loss: 0.3742\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3116 - val_loss: 0.3364\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3085 - val_loss: 0.3315\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3067 - val_loss: 0.3268\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3041 - val_loss: 0.3007\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3035 - val_loss: 0.3021\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3001 - val_loss: 0.3718\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3000 - val_loss: 0.2928\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.2981 - val_loss: 0.3398\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.2963 - val_loss: 0.3362\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.2952 - val_loss: 0.3206\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.2933 - val_loss: 0.3322\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3060 - val_loss: 0.3260\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.2944 - val_loss: 0.4700\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.2941 - val_loss: 0.3229\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.2910 - val_loss: 0.3684\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.2895 - val_loss: 0.3394\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.2889 - val_loss: 0.4344\n",
      "3870/3870 [==============================] - 0s 13us/sample - loss: 0.3227\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=   9.5s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 110us/sample - loss: 0.8243 - val_loss: 1.5916\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4649 - val_loss: 0.4053\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4066 - val_loss: 0.3677\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3815 - val_loss: 0.4618\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3667 - val_loss: 0.3981\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3576 - val_loss: 0.5145\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3496 - val_loss: 0.5006\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3448 - val_loss: 0.8372\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3415 - val_loss: 0.7614\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3362 - val_loss: 0.9335\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3334 - val_loss: 0.6649\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3302 - val_loss: 0.6901\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3264 - val_loss: 0.5174\n",
      "3870/3870 [==============================] - 0s 15us/sample - loss: 0.3355\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=   4.1s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 113us/sample - loss: 1.2088 - val_loss: 2.7444\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5381 - val_loss: 1.0985\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4395 - val_loss: 0.4528\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4048 - val_loss: 0.4281\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3914 - val_loss: 0.4239\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3802 - val_loss: 0.4068\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3736 - val_loss: 0.3784\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3673 - val_loss: 0.3604\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3603 - val_loss: 0.3561\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3562 - val_loss: 0.3580\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3517 - val_loss: 0.3654\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3477 - val_loss: 0.3475\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3466 - val_loss: 0.3393\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3420 - val_loss: 0.3278\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3409 - val_loss: 0.3494\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3388 - val_loss: 0.3663\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3370 - val_loss: 0.3187\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3339 - val_loss: 0.3626\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3311 - val_loss: 0.3404\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3306 - val_loss: 0.3328\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3271 - val_loss: 0.3357\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3272 - val_loss: 0.3110\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3224 - val_loss: 0.3308\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3222 - val_loss: 0.3134\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3207 - val_loss: 0.3086\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3191 - val_loss: 0.4121\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3190 - val_loss: 0.3158\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3160 - val_loss: 0.3313\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3153 - val_loss: 0.3039\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3140 - val_loss: 0.3635\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3114 - val_loss: 0.3214\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3104 - val_loss: 0.3179\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3097 - val_loss: 0.3044\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3081 - val_loss: 0.3085\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3067 - val_loss: 0.3824\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3064 - val_loss: 0.3069\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3029 - val_loss: 0.3598\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3051 - val_loss: 0.3797\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3025 - val_loss: 0.3496\n",
      "3870/3870 [==============================] - 0s 12us/sample - loss: 0.3156\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  10.0s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 112us/sample - loss: 1.4300 - val_loss: 1.5940\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.5219 - val_loss: 60.9819\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.9128 - val_loss: 32.9032\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.6804 - val_loss: 0.5512\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4418 - val_loss: 0.3843\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3853 - val_loss: 0.3772\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3690 - val_loss: 0.3712\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3608 - val_loss: 0.3604\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3545 - val_loss: 0.3623\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3496 - val_loss: 0.3626\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3467 - val_loss: 0.3483\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3431 - val_loss: 0.3489\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3387 - val_loss: 0.3506\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3369 - val_loss: 0.3433\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3331 - val_loss: 0.3349\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3309 - val_loss: 0.3424\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3285 - val_loss: 0.3495\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3268 - val_loss: 0.3381\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3240 - val_loss: 0.3333\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3224 - val_loss: 0.3402\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3183 - val_loss: 0.3239\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3179 - val_loss: 0.3207\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3152 - val_loss: 0.3465\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3145 - val_loss: 0.3243\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3120 - val_loss: 0.3182\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3103 - val_loss: 0.3295\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3085 - val_loss: 0.3391\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3066 - val_loss: 0.3124\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3049 - val_loss: 0.3120\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3031 - val_loss: 0.3358\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3013 - val_loss: 0.3013\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.2993 - val_loss: 0.3170\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.2979 - val_loss: 0.3315\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2974 - val_loss: 0.3009\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2952 - val_loss: 0.3154\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.2931 - val_loss: 0.2975\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.2930 - val_loss: 0.3400\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.2893 - val_loss: 0.3096\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.2882 - val_loss: 0.3312\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.2878 - val_loss: 0.3274\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.2859 - val_loss: 0.3179\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.2847 - val_loss: 0.3261\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2835 - val_loss: 0.2917\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2820 - val_loss: 0.3094\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.2805 - val_loss: 0.2924\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.2793 - val_loss: 0.3467\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.2781 - val_loss: 0.3012\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.2792 - val_loss: 0.3866\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.2757 - val_loss: 0.2986\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.2750 - val_loss: 0.3083\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.2735 - val_loss: 0.2987\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.2714 - val_loss: 0.4106\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.2729 - val_loss: 0.2819\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.2703 - val_loss: 0.2824\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.2697 - val_loss: 0.3205\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2692 - val_loss: 0.3194\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2689 - val_loss: 0.3173\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2650 - val_loss: 0.3151\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.2656 - val_loss: 0.3084\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.2631 - val_loss: 0.2905\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.2624 - val_loss: 0.2825\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.2609 - val_loss: 0.3458\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.2621 - val_loss: 0.3419\n",
      "3870/3870 [==============================] - 0s 15us/sample - loss: 0.3033\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  15.8s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 118us/sample - loss: 0.9839 - val_loss: 0.8577\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4782 - val_loss: 1.8705\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4180 - val_loss: 0.9523\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3892 - val_loss: 0.5136\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3712 - val_loss: 0.4363\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3598 - val_loss: 0.3495\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3517 - val_loss: 0.5520\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3459 - val_loss: 0.3602\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3396 - val_loss: 0.5913\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3369 - val_loss: 0.5060\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3336 - val_loss: 0.4966\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3288 - val_loss: 0.6645\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3258 - val_loss: 0.5405\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3242 - val_loss: 0.6166\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.3213 - val_loss: 0.4948\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3194 - val_loss: 0.4027\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.3395\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=   4.9s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 123us/sample - loss: 0.9957 - val_loss: 5.6306\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5697 - val_loss: 0.5281\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4288 - val_loss: 0.4029\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3969 - val_loss: 0.3840\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3798 - val_loss: 0.3733\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3711 - val_loss: 0.3796\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3629 - val_loss: 0.3474\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3587 - val_loss: 0.3698\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3521 - val_loss: 0.3529\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3492 - val_loss: 0.3408\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3433 - val_loss: 0.4135\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3410 - val_loss: 0.3599\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3376 - val_loss: 0.3762\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3332 - val_loss: 0.3427\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3318 - val_loss: 0.3183\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3275 - val_loss: 0.3267\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3257 - val_loss: 0.3780\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3248 - val_loss: 0.3173\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3223 - val_loss: 0.3461\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3200 - val_loss: 0.3125\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3171 - val_loss: 0.4278\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3166 - val_loss: 0.3209\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3146 - val_loss: 0.3680\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3147 - val_loss: 0.3107\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3131 - val_loss: 0.4073\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3101 - val_loss: 0.3085\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3100 - val_loss: 0.3128\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3088 - val_loss: 0.3234\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3048 - val_loss: 0.4640\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3059 - val_loss: 0.3984\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3038 - val_loss: 0.4763\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3037 - val_loss: 0.4489\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3034 - val_loss: 0.4979\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3029 - val_loss: 0.3137\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3003 - val_loss: 0.3692\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3002 - val_loss: 0.3134\n",
      "3870/3870 [==============================] - 0s 13us/sample - loss: 0.3162\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=   9.5s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 117us/sample - loss: 1.0105 - val_loss: 3.8465\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5459 - val_loss: 7.4493\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5330 - val_loss: 1.2188\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4362 - val_loss: 0.5569\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.4059 - val_loss: 0.4286\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3925 - val_loss: 0.4091\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3834 - val_loss: 0.3987\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3763 - val_loss: 0.3880\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3695 - val_loss: 0.3762\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3648 - val_loss: 0.3944\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3598 - val_loss: 0.3941\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3567 - val_loss: 0.3532\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3530 - val_loss: 0.3738\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3500 - val_loss: 0.3413\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3477 - val_loss: 0.3455\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3461 - val_loss: 0.3474\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3432 - val_loss: 0.3755\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3418 - val_loss: 0.3357\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3400 - val_loss: 0.3495\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3370 - val_loss: 0.3288\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3355 - val_loss: 0.4416\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3354 - val_loss: 0.3443\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3333 - val_loss: 0.3275\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3317 - val_loss: 0.3227\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3301 - val_loss: 0.3200\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3269 - val_loss: 0.4124\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3264 - val_loss: 0.3241\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3243 - val_loss: 0.3433\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3241 - val_loss: 0.3223\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3234 - val_loss: 0.3495\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3218 - val_loss: 0.4068\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3226 - val_loss: 0.3134\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3185 - val_loss: 0.3739\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3181 - val_loss: 0.3282\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3167 - val_loss: 0.3269\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3157 - val_loss: 0.4081\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3157 - val_loss: 0.3171\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3140 - val_loss: 0.3161\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3116 - val_loss: 0.3087\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3112 - val_loss: 0.3986\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3125 - val_loss: 0.4776\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3131 - val_loss: 0.3674\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3101 - val_loss: 0.3079\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3085 - val_loss: 0.3546\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3072 - val_loss: 0.3036\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3060 - val_loss: 0.3238\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3056 - val_loss: 0.3340\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3042 - val_loss: 0.3189\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3041 - val_loss: 0.3375\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3039 - val_loss: 0.3182\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3025 - val_loss: 0.3251\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3006 - val_loss: 0.3338\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3009 - val_loss: 0.3372\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3010 - val_loss: 0.3216\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.2992 - val_loss: 0.3211\n",
      "3870/3870 [==============================] - 0s 14us/sample - loss: 0.3285\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  13.5s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 123us/sample - loss: 1.1561 - val_loss: 1.7767\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5820 - val_loss: 0.6061\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.5056 - val_loss: 1.1016\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.4606 - val_loss: 1.0272\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.4337 - val_loss: 0.6623\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.4157 - val_loss: 0.4443\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.4031 - val_loss: 0.3837\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3940 - val_loss: 0.4111\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3851 - val_loss: 0.4542\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3799 - val_loss: 0.5039\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3738 - val_loss: 0.5838\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3691 - val_loss: 0.6624\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3661 - val_loss: 0.6407\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3629 - val_loss: 0.6865\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3593 - val_loss: 0.7730\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3554 - val_loss: 0.8557\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3537 - val_loss: 0.8921\n",
      "3870/3870 [==============================] - 0s 15us/sample - loss: 0.3731\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=   5.0s\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 123us/sample - loss: 1.0596 - val_loss: 13.9566\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.7935 - val_loss: 10.8332\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5364 - val_loss: 3.2607\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.4762 - val_loss: 0.6638\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4239 - val_loss: 0.4556\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4092 - val_loss: 0.4272\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.4021 - val_loss: 0.4530\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3952 - val_loss: 0.4169\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3907 - val_loss: 0.4624\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3839 - val_loss: 0.3888\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3801 - val_loss: 0.3939\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3759 - val_loss: 0.4272\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3724 - val_loss: 0.4456\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3686 - val_loss: 0.4154\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.3670 - val_loss: 0.3807\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3639 - val_loss: 0.4146\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3645 - val_loss: 0.4090\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3608 - val_loss: 0.4236\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3578 - val_loss: 0.3854\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3547 - val_loss: 0.3579\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3520 - val_loss: 0.4260\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3504 - val_loss: 0.4096\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3499 - val_loss: 0.3582\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3473 - val_loss: 0.3642\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3453 - val_loss: 0.3716\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3446 - val_loss: 0.4443\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3418 - val_loss: 0.3956\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3407 - val_loss: 0.3416\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3389 - val_loss: 0.3585\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3398 - val_loss: 0.3795\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3360 - val_loss: 0.3830\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3342 - val_loss: 0.3744\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3347 - val_loss: 0.3666\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3330 - val_loss: 0.3311\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3316 - val_loss: 0.3621\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3309 - val_loss: 0.3237\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3293 - val_loss: 0.4215\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3286 - val_loss: 0.3699\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3272 - val_loss: 0.3346\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3254 - val_loss: 0.4172\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3257 - val_loss: 0.3690\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3247 - val_loss: 0.3307\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3222 - val_loss: 0.4156\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3238 - val_loss: 0.3112\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3210 - val_loss: 0.4251\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3210 - val_loss: 0.3202\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3182 - val_loss: 0.3758\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3187 - val_loss: 0.3404\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3169 - val_loss: 0.3656\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3166 - val_loss: 0.3698\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3162 - val_loss: 0.3514\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3154 - val_loss: 0.3142\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3143 - val_loss: 0.4188\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3140 - val_loss: 0.3099\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3132 - val_loss: 0.3255\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3117 - val_loss: 0.3137\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3104 - val_loss: 0.3858\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3111 - val_loss: 0.3291\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3099 - val_loss: 0.3085\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3090 - val_loss: 0.3414\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3106 - val_loss: 0.3744\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3080 - val_loss: 0.3024\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3064 - val_loss: 0.4529\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3073 - val_loss: 0.2988\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3057 - val_loss: 0.4660\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3052 - val_loss: 0.2987\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3035 - val_loss: 0.3272\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3033 - val_loss: 0.3019\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3030 - val_loss: 0.4128\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3023 - val_loss: 0.3129\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3012 - val_loss: 0.3592\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3009 - val_loss: 0.3232\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3005 - val_loss: 0.3915\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3004 - val_loss: 0.2993\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2985 - val_loss: 0.3744\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2996 - val_loss: 0.3240\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3058\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  18.1s\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 97us/sample - loss: 0.8564 - val_loss: 8.0393\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4566 - val_loss: 5.5752\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4363 - val_loss: 2.9390\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4034 - val_loss: 0.3701\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3647 - val_loss: 0.3556\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3555 - val_loss: 0.4402\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3490 - val_loss: 0.3389\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3432 - val_loss: 0.3226\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3367 - val_loss: 0.3341\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3335 - val_loss: 0.3160\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3291 - val_loss: 0.3179\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3267 - val_loss: 0.3938\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3232 - val_loss: 0.3123\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3192 - val_loss: 0.4221\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3185 - val_loss: 0.3000\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3144 - val_loss: 0.3166\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3122 - val_loss: 0.2961\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3099 - val_loss: 0.3027\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3074 - val_loss: 0.3589\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3063 - val_loss: 0.3047\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3043 - val_loss: 0.4955\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3037 - val_loss: 0.3250\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3002 - val_loss: 0.3007\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3017 - val_loss: 0.2942\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2973 - val_loss: 0.3619\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2969 - val_loss: 0.2909\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2938 - val_loss: 0.4638\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.2936 - val_loss: 0.2884\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.2922 - val_loss: 0.3430\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.2925 - val_loss: 0.2956\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2889 - val_loss: 0.3481\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2863 - val_loss: 0.3311\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2853 - val_loss: 0.4165\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2844 - val_loss: 0.3715\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2833 - val_loss: 0.3648\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2827 - val_loss: 0.2855\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2812 - val_loss: 0.2902\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2798 - val_loss: 0.2820\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.2797 - val_loss: 0.2848\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.2783 - val_loss: 0.3241\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.2769 - val_loss: 0.2958\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.2765 - val_loss: 0.8862\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2822 - val_loss: 0.8044\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.2804 - val_loss: 0.7344\n",
      "Epoch 45/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.2784 - val_loss: 0.3080\n",
      "Epoch 46/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.2753 - val_loss: 0.2728\n",
      "Epoch 47/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2720 - val_loss: 0.2811\n",
      "Epoch 48/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2716 - val_loss: 0.2754\n",
      "Epoch 49/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.2719 - val_loss: 0.3058\n",
      "Epoch 50/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.2702 - val_loss: 0.2810\n",
      "Epoch 51/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.2679 - val_loss: 0.2797\n",
      "Epoch 52/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.2679 - val_loss: 0.2941\n",
      "Epoch 53/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2677 - val_loss: 0.2962\n",
      "Epoch 54/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.2668 - val_loss: 0.2904\n",
      "Epoch 55/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2672 - val_loss: 0.2752\n",
      "Epoch 56/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.2646 - val_loss: 0.3215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000007CD952BCC0>,\n",
       "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302...\n",
       "                                                          0.005021425736625637,\n",
       "                                                          0.0005703073595961105,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100)               .tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)      .rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "714d72e6-fd6b-4972-b534-cc79f75c19da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 80, 'n_hidden': 3, 'learning_rate': 0.0059640580092043885}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afccab4e-6b19-4dd5-8374-1041c439533e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3196800080971098"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd83cac2-caab-40b6-9a94-1d6db0d21cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 19us/sample - loss: 0.2839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7ceba61a90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.score(X_test, y_test)\n",
    "\n",
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59b1ef1a-186d-42dc-8cca-37e0cbc47320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 21us/sample - loss: 0.2839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2839127619599187"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "35a51493-9746-4843-85d2-97c16cf9d291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5160, 1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prediction=model.predict(X_test)\n",
    "y_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f74503c5-7d41-4def-a552-f2f08694e770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.575810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.269133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.770052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.506607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.991966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5155</th>\n",
       "      <td>4.557382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>0.744896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>1.515116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158</th>\n",
       "      <td>2.557998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>4.222409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5160 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     0.575810\n",
       "1     1.269133\n",
       "2     4.770052\n",
       "3     2.506607\n",
       "4     2.991966\n",
       "...        ...\n",
       "5155  4.557382\n",
       "5156  0.744896\n",
       "5157  1.515116\n",
       "5158  2.557998\n",
       "5159  4.222409\n",
       "\n",
       "[5160 rows x 1 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prediction.astype(\"float\")\n",
    "y_prediction = pd.DataFrame(y_prediction)\n",
    "y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e52e419a-adfb-4504-97a5-ef9fffb825c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.47700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.45800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.18600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.78000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5155</th>\n",
       "      <td>5.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>0.63200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>1.17700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158</th>\n",
       "      <td>2.63100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>4.81500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5160 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0     0.47700\n",
       "1     0.45800\n",
       "2     5.00001\n",
       "3     2.18600\n",
       "4     2.78000\n",
       "...       ...\n",
       "5155  5.00001\n",
       "5156  0.63200\n",
       "5157  1.17700\n",
       "5158  2.63100\n",
       "5159  4.81500\n",
       "\n",
       "[5160 rows x 1 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test=y_test.astype(\"float\")\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b255b3ef-18d4-469e-a7b0-5ba2c17009d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0    0.949306\n",
      "dtype: float64\n",
      "RMSE: 0.5328346479064165\n",
      "MAE: 0.3661768864756314\n",
      "R2b: 0.7854376682457828\n",
      "MSE: 0.28391276200955484\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from pandas import DataFrame\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from gplearn import genetic\n",
    "from gplearn.genetic import SymbolicTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import stats\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.ensemble as ensemble  # ensemble learning: 集成学习\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt#计算准确率xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from numpy import absolute\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "\n",
    "y_prediction=model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_prediction)\n",
    "rmse = mse ** (1/2)\n",
    "sse = np.sum((y_test - y_prediction) ** 2)\n",
    "sst = np.sum((y_test - np.mean(X_test)) ** 2)\n",
    "R2= 1 - sse / sst\n",
    "# r = pearsonr(y_test, y_prediction)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(y_test, y_prediction)\n",
    "print(\"R2:\",R2)\n",
    "print(\"RMSE:\",rmse)\n",
    "\n",
    "print(\"MAE:\",MAE)\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "R2b = r2_score(y_test, y_prediction)\n",
    "MSE = mean_squared_error(y_test, y_prediction)\n",
    "print(\"R2b:\",R2b)\n",
    "print(\"MSE:\",MSE)\n",
    "\n",
    "#plot图\n",
    "plt.yticks(fontproperties = 'Times New Roman', size = 14)\n",
    "plt.xticks(fontproperties = 'Times New Roman', size = 14)\n",
    "plt.rcParams['font.sans-serif'] = 'Roman'\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.plot(y_test, y_test, label='Real Data')\n",
    "plt.scatter(y_test, y_prediction, label='Predict', c='r')\n",
    "ax=plt.gca()\n",
    "ax.spines['bottom'].set_linewidth(2);###设置底部坐标轴的粗细\n",
    "ax.spines['left'].set_linewidth(2);####设置左边坐标轴的粗细\n",
    "ax.spines['right'].set_linewidth(2);###设置右边坐标轴的粗细\n",
    "ax.spines['top'].set_linewidth(2)\n",
    "\n",
    "plt.tick_params(width=2)\n",
    "ax.xaxis.set_tick_params(labelsize=24)\n",
    "plt.tick_params(which='major',length=8)\n",
    "plt.tick_params(which='minor',length=4,width=2)\n",
    "ax.yaxis.set_tick_params(labelsize=24)\n",
    "xminorLocator   = MultipleLocator(1000)\n",
    "yminorLocator   = MultipleLocator(1000)\n",
    "ax.xaxis.set_minor_locator(xminorLocator)\n",
    "ax.yaxis.set_minor_locator(yminorLocator)\n",
    "plt.minorticks_on()\n",
    "\n",
    "plt.xlabel(\"PBE-Eg (eV)\", fontproperties = 'Times New Roman', size = 20)\n",
    "plt.ylabel(\"ML-Eg (eV)\", fontproperties = 'Times New Roman', size = 20)\n",
    "\n",
    "plt.text(2.2, 2.8, 'MAE = %.2f \\nMSE =  %.2f \\nr =  xxx \\n' % (MAE, MSE), fontproperties = 'Times New Roman', size = 20, horizontalalignment='center')\n",
    "plt.savefig('xgboost-test.tif', dpi=300, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dfb993-cc2f-4ace-8207-6dba7b32037e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
